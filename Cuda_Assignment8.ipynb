{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment8_V1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFO-wWmSXuTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "!pip install pytorch_lightning\n",
        "#!pip install --upgrade pytorch_lightning==0.7.6\n",
        "import torch.utils as torchU\n",
        "import pytorch_lightning as torch_light\n",
        "from torchvision import datasets, models, transforms\n",
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THJ3ZYbu5aRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = torch.rand((5,3))\n",
        "print(A)\n",
        "A = A*2-1\n",
        "print(A)\n",
        "A = (A+1)/2\n",
        "print(A)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVWM86YFYyn0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9d9be0a3-d497-45ee-e1d8-6f0ecab87db3"
      },
      "source": [
        "%cd \"/content/drive/My Drive/Colab Notebooks/Cuda Vision lab assignment 8\"\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Cuda Vision lab assignment 8\n",
            "assignment8_V1.ipynb  data  hparams.yaml  lightning_logs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTCHvPptFP4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_network(hparams):\n",
        "  net = []\n",
        "  for ind in range(len(hparams[\"layer_type\"])):\n",
        "    if hparams[\"layer_type\"][ind] == \"maxpool\":\n",
        "      net.append(nn.MaxPool2d(hparams[\"layers\"][ind][0],hparams[\"layers\"][ind][1],hparams[\"layers\"][ind][2]))\n",
        "      continue\n",
        "    if hparams[\"layer_type\"][ind] == \"avgpool\":\n",
        "      net.append(nn.AvgPool2d(hparams[\"layers\"][ind][0],hparams[\"layers\"][ind][1],hparams[\"layers\"][ind][2]))\n",
        "      continue\n",
        "    if hparams[\"layer_type\"][ind] == \"cnn\":\n",
        "      net.append(nn.Conv2d(in_channels=hparams[\"layers\"][ind][0],out_channels=hparams[\"layers\"][ind][1],\n",
        "                                  kernel_size=hparams[\"layers\"][ind][2],stride=hparams[\"layers\"][ind][3],padding=hparams[\"layers\"][ind][4]))\n",
        "      continue\n",
        "    if hparams[\"layer_type\"][ind] == \"cnnt\":\n",
        "      net.append(nn.ConvTranspose2d(in_channels=hparams[\"layers\"][ind][0],out_channels=hparams[\"layers\"][ind][1],\n",
        "                                  kernel_size=hparams[\"layers\"][ind][2],stride=hparams[\"layers\"][ind][3],padding=hparams[\"layers\"][ind][4],\n",
        "                                  output_padding=hparams[\"layers\"][ind][5]))                             \n",
        "      continue\n",
        "    if hparams[\"layer_type\"][ind] == \"tanh\":\n",
        "      net.append(nn.Tanh())\n",
        "      continue\n",
        "    if hparams[\"layer_type\"][ind] == \"sigmoid\":\n",
        "      net.append(nn.Sigmoid())\n",
        "      continue\n",
        "    if hparams[\"layer_type\"][ind] == \"linear\":\n",
        "      net.append(nn.Linear(hparams[\"layers\"][ind][0],hparams[\"layers\"][ind][1]))\n",
        "      continue\n",
        "    if hparams[\"layer_type\"][ind] == \"relu\":\n",
        "      net.append(nn.ReLU())\n",
        "      continue\n",
        "    if hparams[\"layer_type\"][ind] == \"Lrelu\":\n",
        "      net.append(nn.LeakyReLU())\n",
        "      continue\n",
        "    if hparams[\"layer_type\"][ind] == \"dropout\":\n",
        "      net.append(nn.Dropout(hparams[\"layers\"][ind][0]))\n",
        "      continue\n",
        "    if hparams[\"layer_type\"][ind] == \"Bnorm\":\n",
        "      net.append(nn.BatchNorm2d(hparams[\"layers\"][ind][0]))\n",
        "      continue\n",
        "  return nn.Sequential(*net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WboAfsxDFFQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "  Generator class\n",
        "  structure of hparams(dic):\n",
        "    latent_dim: dimension of sample space\n",
        "    layers: array containing the specifications for each layer w.r.t. layer type\n",
        "    layers_type: array containing which type of layers are stacked\n",
        "\"\"\"\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, hparams):\n",
        "        super(Generator, self).__init__()\n",
        "        self.hparams = hparams\n",
        "        self.net = build_network(self.hparams)\n",
        "        \n",
        "    def forward(self, z):\n",
        "        return self.net(z.view(z.shape[0],z.shape[1],1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tYIvp4U5In4Z",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "  Discriminator class\n",
        "  structure of hparams(dic):\n",
        "    latent_dim: dimension of sample space\n",
        "    layers: array containing the specifications for each layer w.r.t. layer type\n",
        "    layers_type: array containing which type of layers are stacked\n",
        "\"\"\"\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, hparams):\n",
        "      super(Discriminator, self).__init__()\n",
        "      self.hparams = hparams\n",
        "      self.net = build_network(self.hparams)\n",
        "      self.d2 = len(self.net)-self.hparams[\"1d\"][0]\n",
        "    \n",
        "    def forward(self, x):\n",
        "      x = self.net[:self.d2](x)\n",
        "      return self.net[self.d2:](x.view(x.shape[0],-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQTJncIfKTaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "  Loading the data_set\n",
        "\"\"\"\n",
        "data_dir = \"/content/drive/My Drive/Colab Notebooks/Cuda Vision lab assignment 8/data\"\n",
        "input_dim = 64\n",
        "data_transforms = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(input_dim),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        #250 dataset\n",
        "        #transforms.Normalize([0.6155, 0.6182, 0.5580],[0.3410, 0.3323, 0.3663])\n",
        "        #new robot dataset\n",
        "        #transforms.Normalize([0.4741, 0.4842, 0.4070],[0.2814, 0.2729, 0.2987])\n",
        "        transforms.Normalize([0.5]*3,[0.5]*3)\n",
        "        ])\n",
        "robot_data_set = datasets.ImageFolder(data_dir,data_transforms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4-VGFOlIquw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "855cf18c-7bea-4d80-a3ca-562830819dde"
      },
      "source": [
        "loader = torchU.data.DataLoader(robot_data_set,batch_size=len(robot_data_set))\n",
        "for batch in loader:\n",
        "  batch, labels = batch\n",
        "  print(batch.max(),batch.min())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.) tensor(-1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xGNWV4ynSmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_means_and_stds(dset):\n",
        "  loader = torchU.data.DataLoader(dset,batch_size=len(dset),shuffle=False, drop_last=True)\n",
        "\n",
        "  for batch in loader:\n",
        "    batch,labels = batch\n",
        "    batch = batch.float().cuda()\n",
        "    means = torch.mean(batch,dim=(0,2,3))\n",
        "    stds = torch.std(batch,dim=(0,2,3))\n",
        "  return means, stds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRuGWfMHv_Fh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b5d07d90-0eff-4893-a812-c577486285e4"
      },
      "source": [
        "# call only once to compute means and std for data sets\n",
        "means,stds = compute_means_and_stds(robot_data_set)\n",
        "print(means,stds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.0508, -0.0264, -0.1823], device='cuda:0') tensor([0.5643, 0.5441, 0.5994], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUzpaKPY_6Bt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(inp,title=None,normalize = False):\n",
        "    inp = torchvision.utils.make_grid(inp)\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    plt.figure(figsize = (30,20))\n",
        "    if normalize:\n",
        "      inp = (inp +1)/2\n",
        "    inp = inp.permute((1, 2, 0))\n",
        "    plt.imshow(inp.detach().cpu())\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFU0Fn5HqHdM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get a batch of training data\n",
        "loader = torchU.data.DataLoader(robot_data_set,batch_size=32,shuffle=True)\n",
        "inputs, classes = next(iter(loader))\n",
        "class_names = robot_data_set.classes\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out,title=[class_names[x] for x in classes],normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArrPXFM371jR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "  pytorch lightning class for GAN\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class GAN(torch_light.LightningModule):\n",
        "\n",
        "    def __init__(self, hparams):\n",
        "      super(GAN, self).__init__()\n",
        "      self.hparams = hparams\n",
        "\n",
        "      # networks\n",
        "      self.generator = Generator(self.hparams[\"gen_hparams\"])\n",
        "      self.discriminator = Discriminator(self.hparams[\"dis_hparams\"])\n",
        "\n",
        "      # cache for generated images\n",
        "      self.generated_imgs = None\n",
        "      self.last_imgs = None\n",
        "      self.img_list = []\n",
        "\n",
        "    def forward(self, z):\n",
        "      return self.generator(z)\n",
        "\n",
        "    def training_step(self, batch, batch_nb, optimizer_idx):\n",
        "      imgs, _ = batch\n",
        "      self.last_imgs = imgs.cuda()\n",
        "\n",
        "      # train generator\n",
        "      if optimizer_idx == 0:\n",
        "          # sample noise\n",
        "          z = torch.randn(imgs.shape[0], (self.hparams[\"gen_hparams\"])[\"latent_dim\"]).cuda()\n",
        "\n",
        "          # generate images\n",
        "          self.generated_imgs = self(z)\n",
        "\n",
        "          # ground truth result (ie: all fake)\n",
        "          # put on GPU because we created this tensor inside training_loop\n",
        "          valid = torch.ones(imgs.size(0), 1).cuda()\n",
        "\n",
        "          # adversarial loss is binary cross-entropy\n",
        "          loss_func = self.get_loss_func()\n",
        "          pred = self.discriminator(self.generated_imgs)\n",
        "          g_loss = loss_func(pred, valid)\n",
        "          self.g_loss = g_loss\n",
        "          self.mean_pred = pred.mean()\n",
        "          return {\"loss\":g_loss}\n",
        "\n",
        "      # train discriminator\n",
        "      if optimizer_idx == 1:\n",
        "          \n",
        "          # Measure discriminator's ability to classify real from generated samples\n",
        "\n",
        "          # how well can it label as real?\n",
        "          valid = torch.ones(imgs.size(0), 1).cuda()\n",
        "\n",
        "          loss_func = self.get_loss_func()\n",
        "          pred = self.discriminator(imgs)\n",
        "          d_loss = loss_func(pred, valid)\n",
        "\n",
        "          # how well can it label as fake?\n",
        "          fake = torch.zeros(imgs.size(0), 1).cuda()\n",
        "\n",
        "          fake_loss = loss_func(\n",
        "              self.discriminator(self.generated_imgs.detach()), fake)\n",
        "\n",
        "          # discriminator loss is the average of these\n",
        "          final_d_loss = d_loss + fake_loss\n",
        "          return {\"loss/dis\": d_loss,\"loss\":final_d_loss,\"loss/gen\" : self.g_loss,\"acc/gen\": self.mean_pred,\"acc/dis\": pred.mean(),\"loss/dis_fake\": fake_loss}\n",
        "    def training_epoch_end(self, outputs):\n",
        "      if self.current_epoch%self.hparams[\"images_saving_per_epoch\"]==0:\n",
        "            self.img_list.append(self.generated_imgs)\n",
        "\n",
        "      avg_loss_g = torch.stack([x['loss/gen'] for x in outputs]).mean()\n",
        "      avg_loss_d = torch.stack([x['loss/dis'] for x in outputs]).mean()\n",
        "      avg_acc_g = torch.stack([x['acc/gen'] for x in outputs]).mean()\n",
        "      avg_acc_d = torch.stack([x['acc/dis'] for x in outputs]).mean()\n",
        "      avg_loss_d_fake = torch.stack([x['loss/dis_fake'] for x in outputs]).mean()\n",
        "      #avg_acc = torch.stack([x['train_acc'] for x in outputs]).mean()\n",
        "      #logs = {'loss/train': avg_loss,'accuracy/train':avg_acc,'step':self.current_epoch}\n",
        "      logs = {'loss/train_gen': avg_loss_g,'loss/train_dis': avg_loss_d,\n",
        "              'step':self.current_epoch,\"acc/gen\":avg_acc_g,\"acc/dis\": avg_acc_d,\"loss/train_dis_fake\": avg_loss_d_fake}\n",
        "      return {'loss_gen_train': avg_loss_g,\"loss_dis_train\":avg_loss_d,'log': logs}\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "      imgs, _ = batch\n",
        "      # sample noise\n",
        "      z = torch.randn(imgs.shape[0], (self.hparams[\"gen_hparams\"])[\"latent_dim\"]).cuda()\n",
        "\n",
        "      # generate images\n",
        "      generated_imgs = self(z)\n",
        "\n",
        "      # ground truth result (ie: all fake)\n",
        "      # put on GPU because we created this tensor inside training_loop\n",
        "      valid = torch.ones(imgs.size(0), 1).cuda()\n",
        "\n",
        "      # adversarial loss is binary cross-entropy\n",
        "      loss_func = self.get_loss_func()\n",
        "      pred = self.discriminator(generated_imgs)\n",
        "      g_loss = loss_func(pred, valid)\n",
        "\n",
        "      # Measure discriminator's ability to classify real from generated samples\n",
        "\n",
        "      # how well can it label as real?\n",
        "      valid = torch.ones(imgs.size(0), 1).cuda()\n",
        "\n",
        "      loss_func = self.get_loss_func()\n",
        "      pred_imgs = self.discriminator(imgs)\n",
        "      d_loss = loss_func(pred_imgs, valid)\n",
        "\n",
        "      # how well can it label as fake?\n",
        "      fake = torch.zeros(imgs.size(0), 1).cuda()\n",
        "\n",
        "      fake_loss = loss_func(\n",
        "          self.discriminator(generated_imgs), fake\n",
        "          )\n",
        "\n",
        "      # discriminator loss is the average of these\n",
        "      final_d_loss = d_loss + fake_loss\n",
        "      return {\"loss_val/dis\": d_loss,\"loss_val/dis_fake\": fake_loss,\"loss_val/gen\" : g_loss,\"acc_val/gen\":pred.mean(),\"acc_val/dis\": pred_imgs.mean()}\n",
        "    def validation_epoch_end(self, outputs):\n",
        "      avg_loss_g = torch.stack([x['loss_val/gen'] for x in outputs]).mean()\n",
        "      avg_loss_d = torch.stack([x['loss_val/dis'] for x in outputs]).mean()\n",
        "      avg_acc_g = torch.stack([x['acc_val/gen'] for x in outputs]).mean()\n",
        "      avg_acc_d = torch.stack([x['acc_val/dis'] for x in outputs]).mean()\n",
        "      avg_loss_d_fake = torch.stack([x['loss_val/dis_fake'] for x in outputs]).mean()\n",
        "      logs = {'loss_val/gen': avg_loss_g,'loss_val/dis': avg_loss_d,\n",
        "              'step':self.current_epoch,\"acc_val/gen\":avg_acc_g,\"acc_val/dis\":avg_acc_d,\"loss_val/dis_fake\": avg_loss_d_fake}\n",
        "      return {'avg_val_loss_gen': avg_loss_g,'avg_val_loss_dis': avg_loss_d, 'log': logs}\n",
        "    def test_step(self, batch, batch_idx):\n",
        "      pass\n",
        "    def test_epoch_end(self, outputs):\n",
        "      pass\n",
        "    def prepare_data(self):\n",
        "      dataset = robot_data_set\n",
        "      #len of dataset is 185\n",
        "      self.trainset, self.valset = torchU.data.random_split(dataset,[150,35]) \n",
        "    def train_dataloader(self):\n",
        "      return torchU.data.DataLoader(self.trainset,self.hparams[\"batch_size\"],shuffle=True,num_workers=4)\n",
        "    def val_dataloader(self):\n",
        "      return torchU.data.DataLoader(self.valset,self.hparams[\"batch_size\"],shuffle=False,num_workers=4)\n",
        "    def configure_optimizers(self):\n",
        "        lr_g = self.hparams[\"learning_rates\"][0]\n",
        "        lr_d = self.hparams[\"learning_rates\"][1]\n",
        "\n",
        "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=lr_g,weight_decay=1e-5)\n",
        "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr_d,weight_decay=1e-4)\n",
        "        lr_scheduler_g = torch.optim.lr_scheduler.StepLR(opt_g,1,0.999)\n",
        "        lr_scheduler_d = torch.optim.lr_scheduler.StepLR(opt_d,1,0.999)\n",
        "        return [opt_g, opt_d], [lr_scheduler_g,lr_scheduler_d]\n",
        "    def get_loss_func(self):\n",
        "      if self.hparams[\"loss_func\"]== \"crossentropy\":\n",
        "        return nn.CrossEntropyLoss()\n",
        "      if self.hparams[\"loss_func\"]== \"mse\":\n",
        "        return nn.MSELoss()\n",
        "      if self.hparams[\"loss_func\"]== \"kl-div\":\n",
        "        return nn.KLDivLoss()\n",
        "      if self.hparams[\"loss_func\"]== \"bceloss\":\n",
        "        return nn.BCELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls5ELQTgB8MJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a582e132-b3bb-450e-9e85-c5688d71bb08"
      },
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/Cuda Vision lab assignment 8 \n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Cuda Vision lab assignment 8\n",
            "assignment8_V1.ipynb  data  hparams.yaml  lightning_logs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWlliupuZZdR",
        "colab_type": "text"
      },
      "source": [
        "# specifications for ConvTranspose2d\n",
        " torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size,\n",
        "                          stride=1, padding=0, output_padding=0,\n",
        "                          groups=1, bias=True)<br>\n",
        " output_height = (height-1) * stride + kernel_size - 2*padding + output_padding\n",
        " # specifications for Conv2d\n",
        " torch.nn.Conv2d(in_channels, out_channels, kernel_size,\n",
        "                 stride=1, padding=0, dilation=1,\n",
        "                 groups=1, bias=True)<br>\n",
        "output_height = (input_height+2*padding)-kernel_size+stride)/stride       "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U97flIO2yKDP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "ade9151f-43d6-412b-a920-e9f78c93a033"
      },
      "source": [
        "\"\"\"\n",
        "  test code for generator\n",
        "\"\"\"\n",
        "\n",
        "d=128\n",
        "deconv1 = nn.ConvTranspose2d(100, d*16, 4, 1, 0)\n",
        "conv = nn.Conv2d(d*8,d*8,3,1,1)\n",
        "deconv2 = nn.ConvTranspose2d(d*16, d*12, 4, 2, 1)\n",
        "deconv3 = nn.ConvTranspose2d(d*12, d*8, 4, 2, 1)\n",
        "deconv4 = nn.ConvTranspose2d(d*8, d*6, 4, 2, 1)\n",
        "deconv5 = nn.ConvTranspose2d(d*6, d*4, 4, 2, 1)\n",
        "deconv6 = nn.ConvTranspose2d(d*4, d*2, 4, 2, 1)\n",
        "deconv7 = nn.ConvTranspose2d(d*2, 3, 4, 2, 1)\n",
        "\n",
        "keep = nn.ConvTranspose2d(d*12,d*12,5,1,2)\n",
        "\n",
        "\n",
        "mini_batch = 25\n",
        "z = torch.randn((mini_batch, 100)).view(-1, 100, 1, 1)\n",
        "print(\"1.st \",z.shape)\n",
        "z = deconv1(z)\n",
        "print(\"2.st \",z.shape)\n",
        "z = deconv2(z)\n",
        "print(\"3.st \",z.shape)\n",
        "z=keep(z)\n",
        "print(\"keep shape: \",z.shape)\n",
        "z = deconv3(z)\n",
        "print(\"4.st \",z.shape)\n",
        "z = conv(z)\n",
        "print(\"same shape? \",z.shape)\n",
        "z = deconv4(z)\n",
        "print(\"5.st \",z.shape)\n",
        "z = deconv5(z)\n",
        "print(\"6.st \",z.shape)\n",
        "z = deconv6(z)\n",
        "print(\"7.st \",z.shape)\n",
        "z = deconv7(z)\n",
        "print(\"8.st \",z.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.st  torch.Size([25, 100, 1, 1])\n",
            "2.st  torch.Size([25, 2048, 4, 4])\n",
            "3.st  torch.Size([25, 1536, 8, 8])\n",
            "keep shape:  torch.Size([25, 1536, 8, 8])\n",
            "4.st  torch.Size([25, 1024, 16, 16])\n",
            "same shape?  torch.Size([25, 1024, 16, 16])\n",
            "5.st  torch.Size([25, 768, 32, 32])\n",
            "6.st  torch.Size([25, 512, 64, 64])\n",
            "7.st  torch.Size([25, 256, 128, 128])\n",
            "8.st  torch.Size([25, 3, 256, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtmea59eWbKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "  hparams for generator\n",
        "\"\"\"\n",
        "latent_dim = 100\n",
        "d=64\n",
        "layers_g = [[latent_dim,d*16,4,1,0,0],[],[d*16],\n",
        "            [d*16,d*16,3,1,1],[],[d*16],\n",
        "\n",
        "            [d*16,d*12,4,2,1,0],[],[d*12],\n",
        "            [d*12,d*12,3,1,1],[],[d*12],\n",
        "\n",
        "            [d*12,d*8,4,2,1,0],[],[d*8],\n",
        "            [d*8,d*8,3,1,1],[],[d*8],\n",
        "\n",
        "            [d*8,d*4,4,2,1,0],[],[d*4],\n",
        "            [d*4,d*4,3,1,1],[],[d*4],\n",
        "            \n",
        "            [d*4,3,4,2,1,0],[],\n",
        "          ]\n",
        "layers_type_g = [\"cnnt\",\"Lrelu\",\"Bnorm\",\n",
        "                 \"cnn\",\"Lrelu\",\"Bnorm\",\n",
        "                 \"cnnt\",\"Lrelu\",\"Bnorm\",\n",
        "                 \"cnn\",\"Lrelu\",\"Bnorm\",\n",
        "                 \"cnnt\",\"Lrelu\",\"Bnorm\",\n",
        "                 \"cnn\",\"Lrelu\",\"Bnorm\",\n",
        "                 \"cnnt\",\"Lrelu\",\"Bnorm\",\n",
        "                 \"cnn\",\"Lrelu\",\"Bnorm\",\n",
        "                 \"cnnt\",\"tanh\"\n",
        "                 ]\n",
        "\n",
        "hparams_g = {}\n",
        "hparams_g[\"latent_dim\"] = latent_dim\n",
        "hparams_g[\"layers\"] = layers_g\n",
        "hparams_g[\"layer_type\"] = layers_type_g"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jRLNXhNm3aiQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "839326f0-42f2-4cc8-be88-31b82d756839"
      },
      "source": [
        "\"\"\"\n",
        "  test code for discriminator\n",
        "\"\"\"\n",
        "\n",
        "d=32\n",
        "conv1 = nn.Conv2d(3, d, 4, 2, 1)\n",
        "conv2 = nn.Conv2d(d, d*2, 4, 2, 1)\n",
        "conv3 = nn.Conv2d(d*2, d*4, 4, 2, 1)\n",
        "conv4 = nn.Conv2d(d*4, d*8, 4, 2, 1)\n",
        "conv5 = nn.Conv2d(d*8, d*10, 4, 2, 1)\n",
        "# conv6 = nn.Conv2d(32, 64, 4, 2, 1)\n",
        "# conv7 = nn.Conv2d(64, 64, 4, 2, 1)\n",
        "# conv8 = nn.Conv2d(64, 100, 4, 2, 1)\n",
        "\n",
        "mini_batch = 16\n",
        "z = torch.randn((mini_batch,3,64,64))\n",
        "print(\"1.st \",z.shape)\n",
        "z = conv1(z)\n",
        "print(\"2.st \",z.shape)\n",
        "z = conv2(z)\n",
        "print(\"3.st \",z.shape)\n",
        "z = conv3(z)\n",
        "print(\"4.st \",z.shape)\n",
        "z = conv4(z)\n",
        "print(\"5.st \",z.shape)\n",
        "z = conv5(z)\n",
        "print(\"6.st \",z.shape)\n",
        "# z = conv6(z)\n",
        "# print(\"7.st \",z.shape)\n",
        "# z = conv7(z)\n",
        "# print(\"8.st \",z.shape)\n",
        "# z = conv8(z)\n",
        "# print(\"9.st \",z.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.st  torch.Size([16, 3, 64, 64])\n",
            "2.st  torch.Size([16, 32, 32, 32])\n",
            "3.st  torch.Size([16, 64, 16, 16])\n",
            "4.st  torch.Size([16, 128, 8, 8])\n",
            "5.st  torch.Size([16, 256, 4, 4])\n",
            "6.st  torch.Size([16, 320, 2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF1iuyl0Wbfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "  hparams for discriminator\n",
        "\"\"\"\n",
        "d=32\n",
        "layers_d = [\n",
        "            [3,d,4,2,1],[],[d],    \n",
        "            [d,d*2,4,2,1],[],[d*2], \n",
        "            [d*2,d*4,4,2,1],[],[d*4], \n",
        "            [d*4,d*8,4,2,1],[],[d*8],\n",
        "            [d*8,d*10,4,2,1],[],[d*10],\n",
        "            [d*10*2*2,2048],[],\n",
        "            [2048,1],[]   \n",
        "          ]\n",
        "layers_type_d = [\"cnn\",\"Lrelu\",\"Bnorm\",\n",
        "                 \"cnn\",\"Lrelu\",\"Bnorm\",\n",
        "                 \"cnn\",\"Lrelu\",\"Bnorm\",\n",
        "                 \"cnn\",\"Lrelu\",\"Bnorm\",\n",
        "                 \"cnn\",\"Lrelu\",\"Bnorm\",\n",
        "                 \"linear\",\"sigmoid\",\n",
        "                 \"linear\",\"sigmoid\"\n",
        "                 ]\n",
        "\n",
        "hparams_d = {}\n",
        "hparams_d[\"layers\"] = layers_d\n",
        "hparams_d[\"layer_type\"] = layers_type_d\n",
        "hparams_d[\"1d\"] = [4,2*2*d*10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEZ6Ggo7g_ed",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "b2b053b0-a4bb-40f8-a659-3e4c1bb632d7"
      },
      "source": [
        "\"\"\"\n",
        " model details:\n",
        "  optimizer are: adam\n",
        "  loss functions given extra as parameter\n",
        "  layer types are:  sigmoid: [input_dim,output_dim]\n",
        "                    linear: [input_dim,output_dim]\n",
        "                    tanh: [input_dim,output_dim]\n",
        "                    relu: [input_dim,output_dim]\n",
        "                    dropout: [dropout_value]\n",
        "                    cnn: [input_channel,output_channel,kernel_size,stride,padding]\n",
        "                    cnnt: [input_channel,output_channel,kernel_size,stride,padding,output_padding]\n",
        "                    max/avgpool: [kernel_size,stride,padding]\n",
        "  layers is a list of list containing the parameters per each layer\n",
        "\"\"\"\n",
        "epoches=3000\n",
        "torch_light.seed_everything()\n",
        "\n",
        "\"\"\"\n",
        "  hparams\n",
        "\"\"\"\n",
        "hparams={}\n",
        "hparams[\"optimizer\"]=\"adam\"\n",
        "hparams[\"learning_rates\"]=[0.00001,0.0000005]\n",
        "hparams[\"batch_size\"]=pow(2,5)\n",
        "hparams[\"gen_hparams\"] = hparams_g\n",
        "hparams[\"dis_hparams\"] = hparams_d\n",
        "hparams[\"loss_func\"]=\"bceloss\"\n",
        "hparams[\"images_saving_per_epoch\"]=50\n",
        "\"\"\"\n",
        "  training and testing\n",
        "\"\"\"\n",
        "net_GAN = GAN(hparams)\n",
        "trainer= torch_light.Trainer(max_epochs=epoches,gpus=-1,fast_dev_run=False,checkpoint_callback=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No correct seed found, seed set to 741594605\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyqGainBX8c_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "  Run training on GAN\n",
        "\"\"\"\n",
        "trainer.fit(net_GAN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUges2xM8_33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "  Save model as checkpoint\n",
        "\"\"\"\n",
        "\n",
        "trainer.save_checkpoint(\"epoches500_lr0.003_0.001_latd512\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjVo6bMT9drM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "  Load model as checkpoint\n",
        "\"\"\"\n",
        "\n",
        "netto = VAE.load_from_checkpoint(\"model_1_MSE_9l_8l.ptl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXHkJxDYSJ-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "  Test the quality of generator images\n",
        "\"\"\"\n",
        "#z_vec = torch.empty(size=((25,256,8,8))).normal_(mean=mean,std=std)\n",
        "z_vec = torch.randn((25,net_GAN.generator.hparams[\"latent_dim\"])).cuda()\n",
        "norm = nn.BatchNorm2d(net_GAN.generator.hparams[\"latent_dim\"]).cuda()\n",
        "#z_vec = norm(z_vec)\n",
        "gen = net_GAN.generator.cuda()\n",
        "images = gen(z_vec)\n",
        "imshow(images,normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYV3SKDteT2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "  Test how generated images changed every x epoches\n",
        "\"\"\"\n",
        "counter = 1\n",
        "for imgs in net_GAN.img_list:\n",
        "  print(\"epoch:\",counter*hparams[\"images_saving_per_epoch\"])\n",
        "  counter+=1\n",
        "  imshow(imgs,normalize=True)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azD2ouw9sC_o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d10b1bf6-ab30-49fa-b66f-82036c4c9f98"
      },
      "source": [
        "%reload_ext tensorboard\n",
        "%cd /content/drive/My Drive/Colab Notebooks/Cuda Vision lab assignment 8 \n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Cuda Vision lab assignment 8\n",
            "assignment8_V1.ipynb  data  hparams.yaml  lightning_logs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1waoqKp9ETk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir lightning_logs"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}